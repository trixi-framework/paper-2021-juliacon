% Allow breaking URLs at hyphens
\PassOptionsToPackage{hyphens}{url}

% JuliaCon proceedings template
\documentclass{juliacon}
\setcounter{page}{1}


% Mathematics is necessary
\usepackage{amsmath}
\allowdisplaybreaks

% Physics rules
\usepackage{siunitx}
% \sisetup{output-exponent-marker=\text{e}}
% \sisetup{tight-spacing=true}

% Use multiple images in a single environment
\usepackage{subcaption}

% Plotting in tikz images
\usepackage{pgfplots}
% Silence warnings
\pgfplotsset{compat=1.16}
% Allow external generation of images to speed up compilation
% \usetikzlibrary{external}
% \tikzexternalize[prefix=../figures/tikz/]

% Macros
\usepackage{xspace}
\newcommand{\ca}[0]{{ca.\@}\xspace}
\newcommand{\cf}[0]{{cf.\@}\xspace}
\newcommand{\eg}[0]{{e.g.\@}\xspace}
\newcommand{\ie}[0]{{i.e.\@}\xspace}
\newcommand{\etc}[0]{{etc.\@}\xspace}
\newcommand{\trixi}{Trixi.jl\xspace}

\newcommand{\todo}[1]{{\color{red}#1}}


\begin{document}

\input{header}

\maketitle

\begin{abstract}
% Abstract: at most 600 characters, written in plain English with no symbol
% nor formula + references etc.
We present Trixi.jl, a Julia library for adaptive high-order numerical simulations
of hyperbolic partial differential equations (PDEs). Utilizing Julia's strengths,
Trixi.jl is extendable, easy to use, and fast. We describe the main design choices
that enable these features and compare Trixi.jl with an established open
source Fortran code for hyperbolic PDEs using the same numerical methods.
We conclude with an assessment of Julia for simulation-focused scientific
computing, an area that is still dominated by traditional high-performance
computing languages such as C, C++, and Fortran.
\end{abstract}


\section{Introduction}

We are broadly interested in simulation-focused scientific computing, in particular
numerical approximations for hyperbolic partial differential equations (PDEs), computational fluid dynamics (CFD),
and related problems. The focus of our research ranges from specific applications
in CFD to general multi-physics coupling strategies to the high-order numerical methods 
such simulations are built upon. In addition, we are academics and involved in teaching 
students in these areas of science. Thus, we would like to have a 
code that is
\begin{enumerate}
  \item extendable to be useful for research and development
  \item easy to apply/understand to be useful for students/collaborators
  \item fast enough to be useful beyond small toy problems
\end{enumerate}
Additionally, we are greedy\footnote{See \url{https://julialang.org/blog/2012/02/why-we-created-julia/}} 
and wish to include all these features within a single code.
Roughly one year of collaborative work has resulted in the current version of
\trixi\footnote{\url{https://github.com/trixi-framework/Trixi.jl}}, providing adaptive
high-order numerical simulations of hyperbolic partial differential equations (PDEs)
in Julia \cite{bezanson2017julia}. Starting as an experiment, we have been able
to reach more and more of our goals with \trixi.

In this article, we present an overview of the main features and design decisions
of \trixi in Section~\ref{sec:design-of-trixi}, laying the ground for an extendable
and easy-to-use framework of high-order methods for hyperbolic PDEs. Next, we
compare the serial performance with an established HPC Fortran code in
Section~\ref{sec:performance-comparison}, demonstrating that Julia is not generically
slower than traditional HPC languages (and can even be faster in this particular case).
Thereafter, we present an assessment of Julia for simulation-focused scientific
computing based on our experience with \trixi in Section~\ref{sec:assessment-of-julia}.
Finally, we summary our findings and conclusions in Section~\ref{sec:summary}.



\section{Design of \trixi and overview of its features}
\label{sec:design-of-trixi}

\trixi is designed as a library of high-order methods for hyperbolic PDEs of
the form
\begin{equation}
\label{eq:hcl}
  \partial_t u(t, x) + \sum_{j=1}^d \partial_{x_j} f^j(u) = s(t, x, u),
  \quad t \in (0, T), x \in \Omega, 
\end{equation}
in $d \in \{1, 2, 3\}$ space dimensions. Here, the independent variables are
time $t$ and space coordinates $x \in \Omega \subset \mathbb{R}^d$. The conserved
quantities are denoted as $u$, \eg, mass, momentum, and energy for the compressible
Euler equations of an ideal gas.
The physical model is specified by the fluxes $f^j$ and the source term $s$.
In addition, suitable initial and boundary conditions (ICs, BCs) are required.
\trixi also handles non-conservative source terms containing derivatives of the
conserved quantities as in the shallow water equations or magnetohydrodynamics
with divergence cleaning.


\subsection{Main features of \trixi}

% TODO: Update Trixi version below
As of version v0.3.50 (July 2021), \trixi concentrates mainly on discontinuous
Galerkin (DG) methods \cite{hesthaven2007nodal, kopriva2009implementing}.
In particular, it has a focus on entropy-conservative and -dissipative methods
\cite{tadmor1987numerical, lefloch2002fully, fisher2013discretely,
ranocha2018comparison, chen2017entropy}. Currently, \trixi comes with the
following features.
\begin{itemize}
  \item 1D, 2D, and 3D simulations on line/quad/hex/simplex meshes
  \begin{itemize}
    \item Cartesian and curvilinear meshes
    \item Conforming and non-conforming meshes
    \item Structured and unstructured meshes
    \item Hierarchical quadtree/octree grid with adaptive refinement
    \item Forests of quadtrees/octrees with \texttt{p4est} \cite{burstedde2011p4est}
          via P4est.jl\footnote{\url{https://github.com/trixi-framework/P4est.jl}}
  \end{itemize}

  \item High-order matrix-free discontinuous Galerkin (DG) methods
  \begin{itemize}
    \item Kinetic energy preserving and entropy-stable methods
    \item Entropy-stable shock-capturing
    \item Positivity-preserving limiting
  \end{itemize}

  \item Multiple governing equations
  \begin{itemize}
    \item Compressible Euler equations (optionally with self-gravity)
    \item Magnetohydrodynamics (MHD) equations
    \item Multicomponent compressible Euler and MHD equations
    \item Acoustic perturbation equations
    \item Hyperbolic diffusion for elliptic problems
    \item Lattice-Boltzmann equations (D2Q9 and D3Q27 schemes)
    \item Several scalar conservation laws (\eg, advection, Burgers)
  \end{itemize}

  \item Integration with the Julia package ecosystem and external tools
  \begin{itemize}
    \item Time integration methods from OrdinaryDiffEq.jl
    \item Automatic differentiation with ForwardDiff.jl
    \item In-situ visualization with Plots.jl
    \item Postprocessing with ParaView/Visit via Trixi2Vtk.jl
  \end{itemize}
\end{itemize}

Some of the main features of \trixi are demonstrated in the following figures.
Figure~\ref{fig:kelvin_helmholtzs} demonstrates entropy-dissipative shock-capturing
methods with adaptive mesh refinement applied to a classical Kelvin-Helmholtz
flow instability problem.

\begin{figure}[htbp]
  \begin{subfigure}{0.53\linewidth}
    \includegraphics[width=\textwidth]{../figures/kelvin_helmholtz_density_t2}
    \caption{Density at time $t = 2$.}
  \end{subfigure}%
  \hspace*{\fill}
  \begin{subfigure}{0.47\linewidth}
    \includegraphics[width=\textwidth]{../figures/kelvin_helmholtz_mesh_t2}
    \caption{Mesh at time $t = 2$.}
  \end{subfigure}%
  \\
  \begin{subfigure}{0.53\linewidth}
    \includegraphics[width=\textwidth]{../figures/kelvin_helmholtz_density_t3}
    \caption{Density at time $t = 3$.}
  \end{subfigure}%
  \hspace*{\fill}
  \begin{subfigure}{0.47\linewidth}
    \includegraphics[width=\textwidth]{../figures/kelvin_helmholtz_mesh_t3}
    \caption{Mesh at time $t = 3$.}
  \end{subfigure}%
  \caption{Numerical solutions of a Kelvin-Helmholtz instability using
           entropy-dissipative shock-capturing methods and adaptive mesh
           refinement for the compressible Euler equations.}
  \label{fig:kelvin_helmholtzs}
\end{figure}

\todo{TODO: Andrew, add gingerbread man example for acoustics} %TODO: Andrew

The detailed physical setups and numerical parameters as well as all code
necessary to reproduce these figures are available in the reproducibility
repository for this article \cite{ranocha2021adaptiveRepro}.


\subsection{High-level overview of the structure}

\trixi is built from the method of lines. Thus, a discretization of \eqref{eq:hcl}
is obtained in two steps. First, a spatial semidiscretization is created. Next,
the resulting ordinary differential equation (ODE) is solved using a time
integration method. Currently, \trixi focuses on the spatial semidiscretization
and uses mostly Runge-Kutta methods implemented in OrdinaryDiffEq.jl, a part
of DifferentialEquations.jl \cite{rackauckas2017differentialequations}.

\begin{figure*}[htbp]
  \includegraphics[width=\linewidth]{../figures/trixi_global_overview}
  \caption{Schematic overview of the basic components in \trixi and how they
           interact.}
  \label{fig:trixi_global_overview}
\end{figure*}

Figure~\ref{fig:trixi_global_overview} presents an overview of the basic
components of \trixi. The most important structure is the semidiscretization,
which bundles all information about the spatial approximation. The mathematical-physical
model is determined by the \lstinline{equations}, the \lstinline{initial_condition},
\lstinline{boundary_conditions}, and possible \lstinline{source_terms}. The
\lstinline{solver} describes purely numerical parameters determining the specific
discretization method such as discontinuous Galerkin or finite difference
methods, kinetic energy preserving or shock capturing approaches. Finally, the
\lstinline{mesh} has a necessarily hybrid role including information about the
spatial domain and its discretization.

Once information about the time span $[0, T]$ is provided, a semidiscretization
in \trixi can be converted into an ODE problem, which can be solved by methods 
from OrdinaryDiffEq.jl. The flexible callback infrastructure of this ODE library
allows us to provide extended functionality for \trixi without modifying any
main loop. In particular, diverse tasks such as input/output operations, adaptive
mesh refinement (AMR), and positivity preserving limiting are implemented using
callbacks.


\subsection{Review of the main design choices}

The design of \trixi was guided by extensibility, ease of use, and efficiency
(in this particular order). Thus, it is likely possible to make (some parts) even 
faster at the cost of simplicity and readibility. Nevertheless, \trixi is already quite
fast, even compared to established high-performance open source software,
as described in detail in Section~\ref{sec:performance-comparison}. In this
section, we focus mostly on the first two goals.

\subsubsection{\trixi is a library}

The most important design decision was to create \trixi as a library. In the
context of simulation-focused scientific computing, there are many (open
or closed source) codes that are designed as monolithic applications that can
simulate a specific setup. These codes can often be configured to a limited extent 
by specifying compile time options or editing parameter files. In contrast, users of 
\trixi do not need to compile anything or learn parameter file syntax. Instead, they can
just load the library and write their simulation setups in Julia. Scripts which describe
a simulation setup for \trixi are referred to as ``elixirs''. As of version v0.3.50, \trixi
comes with \ca 200 example elixirs. A basic elixir might look as follows:
% TODO: Update Trixi version above

\begin{lstlisting}[language = Julia]
# Load all required libraries
using Trixi, OrdinaryDiffEq, Plots

# Set up a 2D linear advection problem with
# advection velocity `a`
a = (1.0, 1.0)
equations = LinearScalarAdvectionEquation2D(a)

# Choose an initial condition coming with Trixi.jl
ic = initial_condition_convergence_test

# Set up a discontinuous Galerkin spectral element
# method with given polynomial degree and surface
# flux implemented in Trixi.jl
solver = DGSEM(polydeg=3,
               surface_flux=flux_lax_friedrichs)

# Create a uniformely refined mesh with periodic
# boundary conditions in a square domain
coordinates_min = (-1.0, -1.0) # lower left
coordinates_max = ( 1.0,  1.0) # upper right
mesh = TreeMesh(coordinates_min, coordinates_max,
                initial_refinement_level=4,
                n_cells_max=10^5, periodicity=true)

# Create semidiscretization with all spatial
# discretization-related components
semi = SemidiscretizationHyperbolic(
  mesh, equations, ic, solver)

# Create an ODE problem from the semidiscretization
# with time span from 0.0 to 1.0
ode = semidiscretize(semi, (0.0, 1.0))

# Evolve the ODE problem in time using `solve` from
# OrdinaryDiffEq with adaptive time stepping
sol = solve(ode, RDPK3SpFSAL49(), abstol=1.0e-6,
  reltol=1.0e-6, save_everystep=false)

# Plot the numerical solution at the final time
plot(sol)
\end{lstlisting}

\subsubsection{Functions are pure Julia functions}

Since functions are first-class citizens in Julia, they can be passed around
and used efficiently. Thus, everything that acts like a function can be used
in \trixi, \eg, to define initial/boundary conditions. While the flexibility
to change initial/boundary conditions
is not too uncommon, two-point numerical fluxes are also just functions with a
specified signature. Thus, users can implement numerical fluxes in their
own code and they will work and be as efficient as if they were implemented
directly in \trixi.

\subsubsection{Ingredients use common interfaces and can be exchanged}

Abstractions such as (variants of) the \lstinline{solver}, the \lstinline{mesh},
and the \lstinline{equations} use a common interface. Utilizing multiple
dispatch in Julia, internal implementations are specialized accordingly. For
example, changing the volume terms of the DG discretization from the standard
weak form to entropy stable and/or shock capturing methods can be achieved by
passing one additional parameter to the \lstinline{DGSEM} constructor in the
example above. Moreover, there is no hidden global state. This means that multiple instances
of similar structures can be instantiated simultaneously. In particular, multiple
semidiscretizations (in possibly different spatial dimensions) can be created
and used in the same code.

\subsubsection{New physics can be specified with minimal effort}

Instead of providing only the very basic discretization ingredients, as with
other open source frameworks for PDEs, \trixi also includes some widely used
physical systems and analysis routines, such as computation of the integrated kinetic energy
for the compressible Euler equations,
to make it easier to use. Nevertheless, users are not restricted
to the physics models bundled in \trixi. To setup a new type of \lstinline{equations},
it is only necessary to create an appropriate \lstinline{struct} bundling all
parameters and implementing pointwise operations such as the calculation of
the fluxes $f^j$ in \eqref{eq:hcl} or two-point numerical fluxes. Due to Julia's
design and just-ahead-of-time compiler, these fluxes can be inlined into the
library functions of \trixi. Thus, the physics can be separated completely from
the \lstinline{solver} but remain computationally efficient. In particular, this allows
a user to reuse the same numerical fluxes for discontinuous Galerkin methods, finite
difference methods, and variants of finite volume methods.

\subsubsection{There is no spooky action at a distance}

In traditional monolithic code bases, it is often necessary to implement a new
feature for all combinations of possible (compile time) options. This effort
can make it difficult to experiment with new ideas. In contrast, Julia's dynamic
nature, multiple dispatch, and just-ahead-of-time compilation allow us to implement only the features
that are strictly necessary. For example, if a user wants to simulate a new
physics model only on Cartesian grids with smooth solutions, there is no need
to implement anything for curvilinear coordinates or shock capturing approaches.
In addition, it allows a user to extend \trixi step by step with new capabilities.
For example, there are ongoing efforts to incorporate summation by parts finite
difference methods via SummationByPartsOperators.jl \cite{ranocha2021sbp} and
discontinuous Galerkin methods on simplex elements via StartUpDG.jl\footnote{\url{https://github.com/jlchan/StartUpDG.jl}} in \trixi.
This is feasible because the modular design of \trixi gives users the flexibility to select
a subset of the available meshes/methods, selected via multiple dispatch,
to test their newly implemented feature(s).



\section{Performance comparison with FLUXO}
\label{sec:performance-comparison}

FLUXO\footnote{\url{https://gitlab.com/project-fluxo/fluxo}} is an open source
MPI Fortran code implementing discontinuous Galerkin methods on unstructured hex
meshes in three space dimensions for advection diffusion equations. It also
implements the same kind of modern DG methods based on flux differencing
to achieve entropy conservation/dissipation or kinetic energy preservation.
At the same time, both codes also have features the other one does not, \eg
parabolic equations and MPI in FLUXO or multiple mesh types and more physics setups
in \trixi. Nevertheless, both \trixi and FLUXO share a common set of features,
enabling a reasonable comparison of their performance.

\todo{TODO: Gregor. Be careful how to formulate this, be neutral and avoid making people angry} %TODO: Gregor

\subsection{Description of the setup}

Here, we compare the serial performance of \trixi and FLUXO when solving a
hyperbolic PDE in three space dimensions on curvilinear hex meshes.

\todo{TODO: Andrew, could you please describe the setups that you used? %TODO Andrew
\begin{itemize}
  \item Physical setup
  \item Numerical methods/parameters
  \item Software versions, compiler \etc
  \item Hardware
\end{itemize}}

The code and detailed information necessary to reproduce these numerical
experiments is available in the accompanying repository \cite{ranocha2021adaptiveRepro}.

\subsection{Results of the performance comparison}

The results of this comparison are visualized in Figure~\ref{fig:PID-Euler}.
Clearly, \trixi is more than 2x faster than the Fortran code FLUXO
while both implement the same numerical methods. This demonstrates the
suitability of Julia for this kind of simulation-focused scientific computing.

\begin{figure}
\centering
  \begin{subfigure}{\linewidth}
    \begin{tikzpicture}[
      font=\footnotesize
      ]
      \begin{axis}[
          xlabel={Polynomial degree},
          % ylabel={Time per RHS call and DOF (seconds)},
          ylabel={Time/RHS/DOF {[sec]}},
          width=\textwidth,
          height=0.66\textwidth,
          legend columns=-1,
          % legend to name=place_legend_here,
          legend pos=north west,
          ymin=0.0,
          ymax=2.2e-6,
          grid=major,
        ]
        \addplot[blue, mark=*, solid] % FLUXO, weak form
          table [x index=0, y index=3]{../data/pids_euler_weak.dat};
          \addlegendentry{FLUXO}
%         \addplot[orange, mark=square*, solid] % TreeMesh, weak form
%           table [x index=0, y index=1]{../data/pids_euler_weak.dat};
%           \addlegendentry{\texttt{TreeMesh} (\trixi)}
        \addplot[red, mark=diamond*, solid] % StructuredMesh, weak form
          table [x index=0, y index=2]{../data/pids_euler_weak.dat};
          % \addlegendentry{\texttt{StructuredMesh} (\trixi)}
          \addlegendentry{\trixi}
        \node at (axis cs:13,3.5e-7) {Weak form};

        \addplot[blue, mark=*, dashed] % FLUXO, flux differencing
          table [x index=0, y index=3]{../data/pids_euler_ranocha.dat};
%         \addplot[orange, mark=square*, dashed] % TreeMesh, flux differencing
%           table [x index=0, y index=1]{../data/pids_euler_ranocha.dat};
        \addplot[red, mark=diamond*, dashed] % StructuredMesh, flux differencing
          table [x index=0, y index=2]{../data/pids_euler_ranocha.dat};
        \node [rotate=23] at (axis cs:9,8.2e-7) {Flux differencing};
        \draw (axis cs:9,9.2e-7) -- (axis cs:7.5,10.2e-7);
        \draw (axis cs:9,7.2e-7) -- (axis cs:8.5,5.2e-7);
      \end{axis}
    \end{tikzpicture}%
    \caption{Absolute run times.}
  \end{subfigure}%
  \\
  \begin{subfigure}{\linewidth}
    \begin{tikzpicture}[
      font=\footnotesize
      ]
      \begin{axis}[
          xlabel={Polynomial degree},
          % ylabel={Time per RHS call and DOF (relative)},
          ylabel={Time relative to FLUXO {[-]}},
          width=\textwidth,
          height=0.66\textwidth,
          legend columns=-1,
          legend pos=south west,
          ymin=0.0,
          ymax=1.1,
          ytick={0, 0.2, 0.4, 0.5, 0.6, 0.8, 1},
          grid=major,
        ]
        \addplot[blue, mark=*, solid, forget plot] % FLUXO, weak form
          table [x index=0, y index=3]{../data/pids_euler_weak_relative.dat};
%         \addplot[orange, mark=square*, solid, forget plot] % TreeMesh, weak form
%           table [x index=0, y index=1]{../data/pids_euler_weak_relative.dat};
        \addplot[red, mark=diamond*, solid] % StructuredMesh, weak form
          table [x index=0, y index=2]{../data/pids_euler_weak_relative.dat};
          \addlegendentry{Weak form}

        \addplot[blue, mark=*, dashed, forget plot] % FLUXO, flux differencing
          table [x index=0, y index=3]{../data/pids_euler_ranocha_relative.dat};
%         \addplot[orange, mark=square*, dashed, forget plot] % TreeMesh, flux differencing
%           table [x index=0, y index=1]{../data/pids_euler_ranocha_relative.dat};
        \addplot[red, mark=diamond*, dashed] % StructuredMesh, flux differencing
          table [x index=0, y index=2]{../data/pids_euler_ranocha_relative.dat};
          \addlegendentry{Flux differencing}
      \end{axis}
    \end{tikzpicture}
    \caption{Run time relative to FLUXO.}
  \end{subfigure}%
  \caption{Run time per right-hand side evaluation and degree of freedom for
           different DG discretizations of the 3D compressible Euler equations.}
  \label{fig:PID-Euler}
\end{figure}

Note that we do not want to state that Julia is generically faster than Fortran,
C, or C++. In contrast, we would like to emphasize that Julia can be at least
as fast as code written in these traditional scientific computing languages.
%We believe that it will be possible to get the same efficiency by rewriting
%FLUXO appropriately. 
Together, the members of our team have strong backgrounds in C, C++, and 
Fortran. Nevertheless, our Julia code is faster than the established HPC Fortran 
code FLUXO for this example. The reason is not that Fortran or Julia are generically 
faster; in contrast, we expect to be able to achieve similar performance from either 
language. Instead, \trixi owes its performance optimizations in part to the code 
introspection and profiling tools available in Julia. Similar tools used to optimize the 
performance in other languages are usually not as easy to use as their Julia 
equivalents (if they exist at all).


Finally, the different mesh types available in \trixi allow further optimizations.
For example, if the computational domain is essentially a cube (or square, line)
without need for curvilinear coordinates, the Cartesian \lstinline{TreeMesh} can
be used. Depending on the relative computational effort of the discretization
(such as the polynomial degree and the choice of the volume terms), the
Cartesian \lstinline{TreeMesh} can be \ca \SI{10}{\percent}--\SI{25}{\percent}
more efficient than the curvilinear meshes in \trixi.

\todo{TODO: Plot of this comparison with the \lstinline{TreeMesh}?}

\todo{TODO: Add MHD results?}



\section{Assessment of Julia for simulation-focused scientific computing}
\label{sec:assessment-of-julia}

Julia was designed from scratch to be useful for numerical computing
\cite{bezanson2017julia}. Its usefulness has been demonstrated for example for
GPU programming \cite{besard2018juliagpu, omlin2020solving},
optimization \cite{dunning2017jump}, data science including
big data\footnote{Celeste project: \url{https://github.com/jeff-regier/Celeste.jl},
see \url{https://juliacomputing.com/case-studies/celeste/} (accessed 2021-07-22)},
machine learning \cite{innes2018fashionable}, and scientific machine learning
(SciML) \cite{pal2021opening}. There are also mature libraries for ODE problems
\cite{rackauckas2017differentialequations}, small scale spectral approximations
\cite{olver2014practical}, and classical finite element methods \cite{badia2020gridap}.
In addition, there are some packages dedicated to solving specific time-dependent
PDEs such as \cite{ramadhan2020oceananigans, constantinou2021geophysicalflows}.
However, there does not seem to be a general framework for high-order methods
for hyperbolic PDEs in Julia. Thus, \trixi is an ideal candidate for a case study
of Julia for simulation-focused scientific computing, an area where codes written
in classical programming languages such as C and Fortran are still dominant
\cite{krais2021flexi, parsani2021ssdc}.

\subsection{What works well}

\subsubsection{Julia is fast}

As demonstrated in Section~\ref{sec:performance-comparison}, there is no reason
why Julia should be generically slower than traditional high-performance programming
languages such as C, C++, and Fortran. A minor exception of this rule is that
Julia is built on LLVM, which does not perform the same optimizations as most
optimizing C/C++/Fortran compilers in use nowadays. In particular, LLVM does
not use fused multiply add (FMA) instructions by default while GCC and Intel
compilers do. Thus, one needs to opt-in to these optimizations explicitly in
Julia. Luckily, that is relatively easy due to Julia's code manipulation
techniques which enable the macro \lstinline{@muladd}\footnote{\url{https://github.com/SciML/MuladdMacro.jl}}.

\subsubsection{Julia encourages good software development practices}

Many scientists implementing numerical methods often have no real experience or
education in software development. Julia and its ecosystem support these
researchers by making it easy to set up unit and regression tests, since a
testing framework is included in the standard library and default package
generation setups prepare the file structure accordingly. This allows test
driven development and continuous integration (CI), which makes code restructuring
and optimization straightforward.

Julia itself and most packages are developed on GitHub. The community provides
many tools to use corresponding CI setups to prepare and publish
documentation\footnote{\url{https://github.com/JuliaDocs/Documenter.jl}},
and related tasks. This setup also encourages other good software development
practices that we use in \trixi, such as mandatory code review before pull requests
are merged.

In addition, the package manager encourages a unified form of semantic versioning
across the Julia ecosystem, which lays the basis for the following three
observations.

\subsubsection{It is easy to set up reproducible numerical experiments}

The package manager makes it easy to reproduce the exact run environment, including
binary dependencies, used to generate numerical results. We have used this feature for all of our papers based on
\trixi \cite{schlottkelakemper2021purely, ranocha2021preventing}, including this
one \cite{ranocha2021adaptiveRepro}.
This facilitates code sharing and reproducible research in computational science,
which is arguably important but not yet mainstream \cite{barnes2010publish,
donoho2010invitation, leveque2013top}.

\subsubsection{External libraries can be integrated relatively easily}

To incorporate some of the adaptive mesh capabilities into \trixi
we have written a Julia wrapper\footnote{\url{https://github.com/trixi-framework/P4est.jl}}
of the C library \texttt{p4est} \cite{burstedde2011p4est}. In our experience,
it is relatively easy to do so in Julia and the package manager in combination
with BinaryBuilder.jl makes it convenient to distribute the necessary binaries.
In particular, users do not have to compile libraries on their own system
and the binaries are available on all major platforms including Linux, macOS,
and Windows.

Similarly, there is no need to compile HDF5 on a user system due to the
availability of HDF5.jl\footnote{\url{https://github.com/JuliaIO/HDF5.jl}}.
There is still work to be done how to improve the experience in combination
with MPI on high performance computing (HPC) clusters, but some promising
approaches exist \cite{byrne2021mpi}.

It is also possible to wrap Fortran libraries/tools in Julia. For example, we
have created the wrappers KROME.jl\footnote{\url{https://github.com/trixi-framework/KROME.jl}}
for KROME, a package to embed chemistry in astrophysical simulations
\cite{grassi2014krome}, and HOHQMesh.jl\footnote{\url{https://github.com/trixi-framework/HOHQMesh.jl}}
for HOHQMesh\footnote{\url{https://github.com/trixi-framework/HOHQMesh}}, a high order
hex-quad mesh generator written in Fortran.

\subsubsection{Packages can be used together at low (or no) cost}

Due to Julia's package manager, the cost of using external dependencies is low
enough to not be a problem. Traditionally, many scientific simulation codes tend
to reduce the number of external dependencies as much as possible due to the
complexity of handling different versions and making everything work together.
Such an approach typically leads to significant code duplication. For example, many
CFD codes implement their own time integration methods, arguing that the spatial
part is much more complex. While this is often true, it is still more efficient
in terms of human workload to be able to reuse existing implementations. This
allows experts on time integration methods to develop specialized algorithms and
implement them in open source software while practitioners or researchers focusing
on spatial semidiscretizations ca benefit immediately by changing only one line
of code. For example, optimized time integration methods were developed in
\cite{ranocha2021optimized} and implemented in OrdinaryDiffEq.jl. These methods
can be used with \trixi by changing a single line of code. In contrast, researchers
working without external dependencies would need to spend a day or two to digest
details before even beginning implementation. This additional overhead in developer
time makes it less likely that researchers would implement these methods in their own 
codes and benefit from recent algorithmic developments. 

An additional example is given by automatic differentiation. Due to dispatch,
it is conveniently possible to use forward mode automatic differentiation
\cite{revels2016forward} to compute Jacobians of semidiscretizations of nonlinear
conservation laws with \trixi or to differentiate through a complete simulation
including time integration methods from OrdinaryDiffEq.jl.

\subsubsection{Julia solves the two-language problem}

Many libraries for simulation-focused scientific computing are written in
languages such as C, C++, or Fortran to get decent performance. On top of these
low-level details, high-level wrappers are often provided to make it easier
for users to apply the algorithms for their problems. In contrast, \trixi is
written completely in Julia.

Such a difference between the programming languages used in the front- and
back-ends lead to a well-known barrier between a user and the developers of a library.
Julia was designed from the beginning to make it possible to write both simple
high-level code and highly efficient compute kernels, thereby solving the
two-language problem --- at least to a significant extent. Highly efficient low-level
code will of course still look different from simple high-level code, but the
barrier between them is much smaller. In particular, this makes it easier for
users to transition to developers and contribute to a package. This also contributes
to the following observation:

\subsubsection{The code base is simple enough to be useful for new users}

Due to the package manager, \trixi and all related ODE and visualization tools
can be installed with a single command, reducing the overhead of exploring the
code. In addition, Julia's expressiveness and the ability to work with a restricted
subset of all possible features have enabled more than 18 students to use \trixi
for their coursework or theses. In our experience, the time required to get
started with traditional monolithic code bases is so long that students either
choose to build their own implementations specialized on their tasks or can only
work on toy problems since the remaining time is rather restricted. 

Another anecdotal example of ease of use is the preprint \cite{singh2021linear}. 
While the authors utilized \trixi for some numerical experiments, they did so 
independently of the development team (who learned that the authors were 
using \trixi only \textit{after} reading the preprint!). 

\subsubsection{Existing features can be extended and combined easily}

Due to Julia's high-level programming approach, dynamic typing, and multiple
dispatch, it is easy to combine existing functionality efficiently. For example,
the single-physics solvers for hyperbolic PDEs of \trixi were extended to
a multi-physics setup for the compressible Euler equations with self-gravity
with roughly 350 lines of code \cite{schlottkelakemper2021purely}.
In addition, \trixi can be extended from the outside without modifying the main
source code, which makes it easy to set up new simulation approaches and analyze
existing ones, \eg by fluctuation simulations \cite{ranocha2021preventing}.

\subsubsection{Julia is free}

Julia itself is released under the MIT license and ships some GPL-licensed
third-party software (that can optionally be disabled for commercial purposes).
Many packages in the Julia ecosystem follow this approach and are freely available
under the permissive MIT license, including \trixi. This allows programmers to use Julia
without needing to pay for commercial software. In particular, students can
work with the software on their private computers without restrictions.


\subsection{What is still difficult or unknown}

\subsubsection{Compilation times can be annoying}

Since Julia uses a serial just-ahead-of-time compiler that currently does not cache
code between different Julia sessions, the initial compilation time can be
annoying. For example, the time to finish a first \trixi simulation in a fresh Julia
session and plot the results on a notebook can take between 30 seconds and a
minute. Having compiled the code, the second simulation and plot takes less than
0.05 seconds. Thus, switching to Julia requires adapting the workflow compared
to other languages such as keeping a REPL session active for a longer time and
using packages such as Revise.jl\footnote{\url{https://github.com/timholy/Revise.jl}}.
This is particularly problematic in HPC environments. There are tools such as
PackageCompiler.jl\footnote{\url{https://github.com/JuliaLang/PackageCompiler.jl}}
that can help with these tasks but a good workflow usable for development and
deployment still has to be found.

\subsubsection{MPI-based parallel simulations need to be established}

MPI: To be evaluated but the basic tools are already there \cite{byrne2021mpi}

\todo{TODO: Michael, could you please write something here? You are much more
experienced with MPI and HPC. Be aware of \cite{omlin2020solving} to not step
on anybodies toes...} %TODO Michael


\section{Summary and conclusions}
\label{sec:summary}

We have presented \trixi, a Julia library for adaptive high-order numerical
simulations of hyperbolic PDEs. As researchers in numerical analysis and
scientific computing, our goals were to create a framework that is extendable,
easy to use, and fast (in this particular order). Making use of Julia's strengths,
we have been successful based on recent publications making use of \trixi,
the number of students and researchers working with \trixi, and serial performance
comparisons with an established Fortran code. Having developed, from scratch, \trixi for a bit
more than one year allows us to give an assessment of Julia for simulation-focused
scientific computing.

Based on our experience, we consider Julia to be suitable for simulation-focused
scientific computing, in particular for hyperbolic PDEs, computational fluid
dynamics, and related problems --- at least on the scale of shared memory
parallelism. The scalability of high-order methods for hyperbolic PDEs written
in Julia to high performance computing applications still needs to be demonstrated.
However, we do not expect this to remain an unsolvable problem since Julia is not 
generically slower than traditional compiled HPC programming languages. Nevertheless, 
it appears to be more complicated to scale Julia to HPC while still keeping the
code as simple, clean, and flexible as it is now.

Learning a new programming language requires of course some effort and needs some
time. Nevertheless, it has paid off in our experience and we do not want to miss the
nice features of \trixi enabled by Julia and its ecosystem. Thus, while there is
of course no need to switch to Julia if people are satisfied with their existing
tools, we encourage researchers to try out Julia and stay for a while. The Julia
community (on the Julia Discourse forum\footnote{\url{https://discourse.julialang.org/}}
or Slack/Zulip workspaces) is usually welcoming and helpful, both for new and
experienced users. Making use of existing learning material and asking questions
appears to be important since a new programming style is necessary to make full
use of all of Julia's strengths.



\section*{Acknowledgments}

We would like to thank all other contributors to and users of \trixi for their
help, encouragement, and discussions.
Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
under Germany's Excellence Strategy EXC 2044-390685587, Mathematics Münster:
Dynamics-Geometry-Structure.
Andrew Winters was funded through Vetenskapsr{\aa}det, Sweden grant
agreement 2020-03642 VR.

The performance computations were enabled by resources provided by the Swedish National
Infrastructure for Computing (SNIC) at Tetralith partially funded by the Swedish
Research Council through grant agreement no. 2018-05973.

\todo{TODO: Add your funding sources that need to be here (if any)} %TODO Funding

Jesse Chan acknowledges support from the US National Science Foundation under 
awards DMS-1719818 and DMS-1943186. 
% References
\input{bib.tex}


\todo{ % TODO
\begin{itemize}
  \item Full paper: 5--10 pages
  \item Prepare repro repo including scripts for \trixi and FLUXO
  \item Rerun Euler benchmarks and add MHD benchmarks
  \item Shall we re-create the schematic overview in tikz?
  \item Gregor: Other aspects of other codes that we like more in \trixi?
  \item Are there other aspects we should discuss?
  \item Check affiliations
\end{itemize}
\begin{quote}
  Compared to an extended abstract, a full paper presents more of the background
  and context motivating the work. It compares the work to other approaches taken
  in the field and gives some additional insights on the conference contribution.
  Use cases back up the work by showing how it can be used.
\end{quote}}


\end{document}

% Inspired by the International Journal of Computer Applications template
