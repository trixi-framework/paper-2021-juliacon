
% JuliaCon proceedings template
\documentclass{juliacon}
\setcounter{page}{1}


% Mathematics is necessary
\usepackage{amsmath}
\allowdisplaybreaks

% Physics rules
\usepackage{siunitx}
% \sisetup{output-exponent-marker=\text{e}}
% \sisetup{tight-spacing=true}

% Use multiple images in a single environment
\usepackage{subcaption}

% Plotting in tikz images
\usepackage{pgfplots}
% Silence warnings
\pgfplotsset{compat=1.16}
% Allow external generation of images to speed up compilation
% \usetikzlibrary{external}
% \tikzexternalize[prefix=../figures/tikz/]

% Macros
\usepackage{xspace}
\newcommand{\ca}[0]{{ca.\@}\xspace}
\newcommand{\cf}[0]{{cf.\@}\xspace}
\newcommand{\eg}[0]{{e.g.\@}\xspace}
\newcommand{\ie}[0]{{i.e.\@}\xspace}
\newcommand{\etc}[0]{{etc.\@}\xspace}
\newcommand{\trixi}{Trixi.jl\xspace}

\newcommand{\todo}[1]{{\color{red}#1}}


\begin{document}

\input{header}

\maketitle

\begin{abstract}
% Abstract: at most 600 characters, written in plain English with no symbol
% nor formula + references etc.
We present Trixi.jl, a Julia library for adaptive high-order numerical simulations
of hyperbolic partial differential equations (PDEs). Utilizing Julia's strengths,
Trixi.jl is extendable, easy to use, and fast. We describe the main design choices
that allow satisfying these goals and compare Trixi.jl with an established open
source Fortran code for hyperbolic PDEs using the same numerical methods.
We conclude with an assessment of Julia for simulation-focused scientific
computing, an area that is still dominated by traditional high-performance
computing languages such as C, C++, and Fortran.
\end{abstract}


\section{Introduction}

\trixi\footnote{https://github.com/trixi-framework/Trixi.jl} provides adaptive
high-order numerical simulations of hyperbolic partial differential equations (PDEs).
in Julia \cite{bezanson2017julia}.

\todo{TODO %TODO Introduction
\begin{itemize}
  \item Why we created \trixi
  \item Overview of the paper \etc
\end{itemize}}



\section{Design of \trixi and overview of its features}

\trixi is designed as a library of high-order methods for hyperbolic PDEs of
the form
\begin{equation}
\label{eq:hcl}
  \partial_t u(t, x) + \sum_{j=1}^d \partial_{x_j} f^j(u) = s(t, x, u),
  \quad t \in (0, T), x \in \Omega,
\end{equation}
in $d \in \{1, 2, 3\}$ space dimensions. Here, the independent variables are
time $t$ and space coordinates $x \in \Omega \subset \mathbb{R}^d$. The conserved
quantities are denoted as $u$, \eg, mass, momentum, and energy for the compressible
Euler equations of an ideal gas.
The physical model is specified by the fluxes $f^j$ and the source term $s$.
In addition, suitable initial and boundary conditions (ICs, BCs) are required.
\trixi also handles non-conservative source terms containing derivatives of the
conserved quantities as in the shallow water equations or magnetohydrodynamics
with divergence cleaning.


\subsection{Main features of \trixi}

As of version v0.3.47 (July 2021), \trixi comes with the following features.
\begin{itemize}
  \item 1D, 2D, and 3D simulations on line/quad/hex meshes
  \begin{itemize}
    \item Cartesian and curvilinear meshes
    \item Conforming and non-conforming meshes
    \item Structured and unstructured meshes
    \item Hierarchical quadtree/octree grid with adaptive refinement
  \end{itemize}

  \item High-order nodal discontinuous Galerkin methods
  \begin{itemize}
    \item Kinetic energy preserving and entropy-stable methods
    \item Entropy-stable shock-capturing
    \item Positivity-preserving limiting
  \end{itemize}

  \item Multiple governing equations
  \begin{itemize}
    \item Compressible Euler equations (optionally with self-gravity)
    \item Magnetohydrodynamics equations
    \item Acoustic perturbation equations
    \item Hyperbolic diffusion for elliptic problems
    \item Lattice-Boltzmann equations (D2Q9 and D3Q27 schemes)
    \item Several scalar conservation laws (advection, Burgers)
  \end{itemize}

  \item Integration with the Julia package ecosystem and external tools
  \begin{itemize}
    \item Time integration methods from OrdinaryDiffEq.jl
    \item Automatic differentiation with ForwardDiff.jl
    \item In-situ visualization with Plots.jl
    \item Postprocessing with ParaView/Visit via Trixi2Vtk.jl
  \end{itemize}
\end{itemize}


\subsection{High-level overview of the structure}

\trixi is based on the method of lines. Thus, a discretization of \eqref{eq:hcl}
is obtained in two steps. First, a spatial semidiscretization is created. Next,
the resulting ordinary differential equation (ODE) is solved using a time
integration method. Currently, \trixi focuses on the spatial semidiscretization
and uses mostly Runge-Kutta methods implemented in OrdinaryDiffEq.jl, a part
of DifferentialEquations.jl \cite{rackauckas2017differentialequations}.

\begin{figure*}[htbp]
  \includegraphics[width=\linewidth]{../figures/trixi_global_overview}
  \caption{Schematic overview of the basic components of \trixi and how they
           interact with each other.}
  \label{fig:trixi_global_overview}
\end{figure*}

Figure~\ref{fig:trixi_global_overview} presents an overview of the basic
components of \trixi. The most important structure is the semidiscretization,
which bundles all information about the spatial part. The mathematical-physical
model is determined by the \lstinline{equations}, the \lstinline{initial_condition},
\lstinline{boundary_conditions}, and possible \lstinline{source_terms}. The
\lstinline{solver} describes purely numerical parameters determining the specific
discretization method such as discontinuous Galerkin or finite difference
methods, kinetic energy preserving or shock capturing approaches. Finally, the
\lstinline{mesh} has a necessarily hybrid role including information about the
spatial domain and its discretization.

Adding information about the time span $[0, T]$, a semidiscretization of \trixi
can be converted into an ODE problem, which can be solved by methods from
OrdinaryDiffEq.jl. The flexible callback infrastructure of this ODE library
allows us to provide extended functionality for \trixi without modifying any
main loop. In particular, diverse tasks such as input/output operations, adaptive
mesh refinement (AMR), and positivity preserving limiting are implemented using
callbacks.


\subsection{Review of the main design choices}

The design of \trixi was guided by extensibility, ease of use, and efficiency
(in this particular order). Thus, it will likely be possible to make (some parts)
even faster while sacrificing simplicity. Nevertheless, \trixi is already quite
fast, even compared to established high-performance open source software,
as described in details in Section~\ref{sec:performance-comparison}. In this
section, we focus mostly on the first two goals.

\subsubsection{\trixi is a library}

The most important design decision was to create \trixi as a library. In the
context of simulation-focused scientific computing, there are a lot of (open
or closed source) codes that are designed as monolithic applications that can
simulate a specific setup. They can often be configured in limited amounts by
compile time options and parameter files. In contrast, users of \trixi do not
need to compile anything or learn the syntax of parameter files. They just load
the library and write their simulation setups in Julia. Such scripts describing
a simulation setup for \trixi are called elixirs. As of version v0.3.43, \trixi
comes with \ca 200 example elixirs. A basic elixir could look as follows.

\begin{lstlisting}[language = Julia]
# Load all required libraries
using Trixi, OrdinaryDiffEq, Plots

# Set up a 2D linear advection problem with
# advection velocity `a`
a = (1.0, 1.0)
equations = LinearScalarAdvectionEquation2D(a)

# Choose an initial condition coming with Trixi.jl
ic = initial_condition_convergence_test

# Set up a discontinuous Galerkin spectral element
# method with given polynomial degree and surface
# flux implemented in Trixi.jl
solver = DGSEM(polydeg=3,
               surface_flux=flux_lax_friedrichs)

# Create a uniformely refined mesh with periodic
# boundary conditions in a square domain
coordinates_min = (-1.0, -1.0) # lower left
coordinates_max = ( 1.0,  1.0) # upper right
mesh = TreeMesh(coordinates_min, coordinates_max,
                initial_refinement_level=4,
                n_cells_max=10^5, periodicity=true)

# Create semidiscretization with all spatial
# discretization-related components
semi = SemidiscretizationHyperbolic(
  mesh, equations, ic, solver)

# Create an ODE problem from the semidiscretization
# with time span from 0.0 to 1.0
ode = semidiscretize(semi, (0.0, 1.0))

# Evolve the ODE problem in time using `solve` from
# OrdinaryDiffEq with adaptive time stepping
sol = solve(ode, RDPK3SpFSAL49(), abstol=1.0e-6,
  reltol=1.0e-6, save_everystep=false)

# Plot the numerical solution at the final time
plot(sol)
\end{lstlisting}

\subsubsection{Functions are pure Julia functions}

Since functions are first-class citizens in Julia, they can be passed around
and used efficiently. Thus, everything that acts like a function can be used
in \trixi, \eg, to define initial/boundary conditions. While such a flexibility
is not too uncommon, two-point numerical fluxes are also just functions with a
specified signature. Thus, users can implement numerical fluxes in their
own code and they will work and be as efficient as if they were implemented
directly in \trixi.

\subsubsection{Ingredients use common interfaces and can be exchanged}

Abstractions such as (variants of) the \lstinline{solver}, the \lstinline{mesh},
and the \lstinline{equations} are based on a common interface. Using multiple
dispatch in Julia, internal implementations are specialized accordingly. For
example, changing the volume terms of the DG discretization from the standard
weak form to entropy stable and/or shock capturing methods can be achieved by
passing one additional parameter to the \lstinline{DGSEM} constructor in the
example above.

\subsubsection{New physics can be specified with minimal effort}

Instead of providing only the very basic discretization ingredients such as
other open source frameworks for PDEs, \trixi includes also some widely used
physical parts to make it easier to use. Nevertheless, users are not restricted
to the physics models bundled in \trixi. To setup a new type of \lstinline{equations},
it is only necessary to create an appropriate \lstinline{struct} bundling all
parameters and implementing pointwise operations such as the calculation of
the fluxes $f^j$ in \eqref{eq:hcl} or two-point numerical fluxes. Due to Julia's
design and just-ahead-of-time compiler, these fluxes can be inlined into the
library functions of \trixi. Thus, the physics can be separated completely from
the \lstinline{solver} but are still very efficient.

\subsubsection{There is no spooky action at a distance}

In traditional monolithic code bases, it is often necessary to implement a new
feature for all combinations of possible (compile time) options. This effort
can make it hard to experiment with new ideas. In contrast, Julia's dynamic
nature and just-ahead-of-time compiler allow us to implement only the features
that are strictly necessary. For example, if a user wants to simulate a new
physics model only on Cartesian grids with smooth solutions, there is no need
to implement anything for curvilinear coordinates or shock capturing approaches.
In addition, it allows to extend \trixi step by step with new capabilities.
For example, there are ongoing efforts to incorporate summation by parts finite
difference methods via SummationByPartsOperators.jl \cite{ranocha2021sbp} and
discontinuous Galerkin methods on simplices via StartUpDG.jl\footnote{\url{https://github.com/jlchan/StartUpDG.jl}} in \trixi. This becomes feasible since not every
feature combination needs to be considered and it is totally fine to start with
simple variants on a subset of the available meshes.



\section{Performance comparison with FLUXO}
\label{sec:performance-comparison}

FLUXO\footnote{\url{https://gitlab.com/project-fluxo/fluxo}} is an open source
MPI Fortran code implementing discontinuous Galerkin methods on unstructured hex
meshes in three space dimensions for advection diffusion equations. It also
implements the same kind of modern DG methods based on flux differencing
to achieve entropy conservation/dissipation or kinetic energy preservation.
Thus, both \trixi and FLUXO share a common set of features, enabling a reasonable
comparison of their performance.

\subsection{Description of the setup}

Here, we compare the serial performance of \trixi and FLUXO when solving a
hyperbolic PDE in three space dimensions on curvilinear hex meshes.

\todo{TODO: Andrew, please describe the setups that you used} %TODO Andrew

The code and detailed information necessary to reproduce these numerical
experiments is available in the accompanying repository \cite{ranocha2021adaptiveRepro}.

\subsection{Results of the performance comparison}

The results of this comparison are visualized in Figure~\ref{fig:PID-Euler}.
Clearly, \trixi is more than 2x faster than the Fortran code FLUXO
while both implement the same numerical methods. This demonstrates the
suitability of Julia for this kind of simulation-focused scientific computing.

\begin{figure}
\centering
  \begin{subfigure}{\linewidth}
    \begin{tikzpicture}[
      font=\footnotesize
      ]
      \begin{axis}[
          xlabel={Polynomial degree},
          % ylabel={Time per RHS call and DOF (seconds)},
          ylabel={Time/RHS/DOF {[sec]}},
          width=\textwidth,
          height=0.66\textwidth,
          legend columns=-1,
          % legend to name=place_legend_here,
          legend pos=north west,
          ymin=0.0,
          ymax=2.2e-6,
          grid=major,
        ]
        \addplot[blue, mark=*, solid] % FLUXO, weak form
          table [x index=0, y index=3]{../data/pids_euler_weak.dat};
          \addlegendentry{FLUXO}
%         \addplot[orange, mark=square*, solid] % TreeMesh, weak form
%           table [x index=0, y index=1]{../data/pids_euler_weak.dat};
%           \addlegendentry{\texttt{TreeMesh} (\trixi)}
        \addplot[red, mark=diamond*, solid] % StructuredMesh, weak form
          table [x index=0, y index=2]{../data/pids_euler_weak.dat};
          % \addlegendentry{\texttt{StructuredMesh} (\trixi)}
          \addlegendentry{\trixi}
        \node at (axis cs:13,3.5e-7) {Weak form};

        \addplot[blue, mark=*, dashed] % FLUXO, flux differencing
          table [x index=0, y index=3]{../data/pids_euler_ranocha.dat};
%         \addplot[orange, mark=square*, dashed] % TreeMesh, flux differencing
%           table [x index=0, y index=1]{../data/pids_euler_ranocha.dat};
        \addplot[red, mark=diamond*, dashed] % StructuredMesh, flux differencing
          table [x index=0, y index=2]{../data/pids_euler_ranocha.dat};
        \node [rotate=23] at (axis cs:9,8.2e-7) {Flux differencing};
        \draw (axis cs:9,9.2e-7) -- (axis cs:7.5,10.2e-7);
        \draw (axis cs:9,7.2e-7) -- (axis cs:8.5,5.2e-7);
      \end{axis}
    \end{tikzpicture}%
    \caption{Absolute run times.}
  \end{subfigure}%
  \\
  \begin{subfigure}{\linewidth}
    \begin{tikzpicture}[
      font=\footnotesize
      ]
      \begin{axis}[
          xlabel={Polynomial degree},
          % ylabel={Time per RHS call and DOF (relative)},
          ylabel={Time relative to FLUXO {[-]}},
          width=\textwidth,
          height=0.66\textwidth,
          legend columns=-1,
          legend pos=south west,
          ymin=0.0,
          ymax=1.1,
          ytick={0, 0.2, 0.4, 0.5, 0.6, 0.8, 1},
          grid=major,
        ]
        \addplot[blue, mark=*, solid, forget plot] % FLUXO, weak form
          table [x index=0, y index=3]{../data/pids_euler_weak_relative.dat};
%         \addplot[orange, mark=square*, solid, forget plot] % TreeMesh, weak form
%           table [x index=0, y index=1]{../data/pids_euler_weak_relative.dat};
        \addplot[red, mark=diamond*, solid] % StructuredMesh, weak form
          table [x index=0, y index=2]{../data/pids_euler_weak_relative.dat};
          \addlegendentry{Weak form}

        \addplot[blue, mark=*, dashed, forget plot] % FLUXO, flux differencing
          table [x index=0, y index=3]{../data/pids_euler_ranocha_relative.dat};
%         \addplot[orange, mark=square*, dashed, forget plot] % TreeMesh, flux differencing
%           table [x index=0, y index=1]{../data/pids_euler_ranocha_relative.dat};
        \addplot[red, mark=diamond*, dashed] % StructuredMesh, flux differencing
          table [x index=0, y index=2]{../data/pids_euler_ranocha_relative.dat};
          \addlegendentry{Flux differencing}
      \end{axis}
    \end{tikzpicture}
    \caption{Run time relative to FLUXO.}
  \end{subfigure}%
  \caption{Run time per right-hand side evaluation and degree of freedom for
           different DG discretizations of the 3D compressible Euler equations.}
  \label{fig:PID-Euler}
\end{figure}

Note that we do not want to state that Julia is generically faster than Fortran,
C, or C++. In contrast, we would like to emphasize that Julia can be at least
as fast as code written in these traditional scientific computing languages.
We believe that it will be possible to get the same efficiency by rewriting
FLUXO appropriately. However, the code introspection and profiling tools available
in Julia make it easier for us to optimize Julia code compared to other languages
we are familiar with (having a diverse team with a strong background in C, C++,
and Fortran).

Finally, the different mesh types available in \trixi allow further optimizations.
For example, if the computational domain is essentially a cube (or square, line)
without need for curvilinear coordinates, the Cartesian \lstinline{TreeMesh} can
be used. Depending on the relative computational effort of the discretization
(such as the polynomial degree and the choice of the volume terms), the
Cartesian \lstinline{TreeMesh} can be \ca \SI{10}{\percent}--\SI{25}{\percent}
more efficient than the curvilinear meshes in \trixi.

\todo{TODO: Plot of this comparison with the \lstinline{TreeMesh}?}



\section{Assessment of Julia for simulation-focused scientific computing}

Julia was designed from scratch to be useful for numerical computing
\cite{bezanson2017julia}. Its usefulness has been demonstrated for example for
optimization \cite{dunning2017jump}, data science including
big data\footnote{Celeste project: \url{https://github.com/jeff-regier/Celeste.jl},
see \url{https://juliacomputing.com/case-studies/celeste/} (accessed 2021-07-22)},
machine learning \cite{innes2018fashionable}, and scientific machine learning
(SciML) \cite{pal2021opening}. There are also mature libraries for ODE problems
\cite{rackauckas2017differentialequations}, small scale spectral approximations
\cite{olver2014practical}, and classical finite element methods \cite{badia2020gridap}.
In addition, there are some packages dedicated to solve specific time-dependent
PDEs such as \cite{ramadhan2020oceananigans, constantinou2021geophysicalflows}.
However, there does not seem to be a general framework of high-order methods
or hyperbolic PDEs in Julia. Thus, \trixi is an ideal candidate for a case study
of Julia for simulation-focused scientific computing, an area where codes written
in classical programming languages such as C and Fortran are still dominant
\cite{krais2021flexi, parsani2021ssdc}.

\subsection{What works well}

\subsubsection{Julia is fast}

As demonstrated in Section~\ref{sec:performance-comparison}, there is no reason
why Julia should be generically slower than traditional high-performance programming
languages such as C, C++, and Fortran. A minor exception of this rule is that
Julia is build on LLVM, which does not perform the same optimizations as most
optimizing C/C++/Fortran compilers in use nowadays. In particular, LLVM does
not use fused multiply add (FMA) instructions by default while GCC and Intel
compilers do. Thus, one needs to opt-in to these optimizations explicitly in
Julia. Luckily, that is relatively easy to do due to Julia's code manipulation
techniques which enable the macro \lstinline{@muladd}\footnote{\url{https://github.com/SciML/MuladdMacro.jl}}.

\subsubsection{Julia encourages good software development practices}

Many scientists implementing numerical methods often have no real experience or
education in software development. Julia and its ecosystem support these
researches by making it easy to set up unit and regression tests, since a
testing framework is included in the standard library and default package
generation setups prepare the file structure accordingly. This allows test
driven development and continuous integration (CI), which makes code restructuring
and optimization feasible.

In addition, the package manager encourages a unified form of semantic versioning
across the Julia ecosystem, which lays the basis for the following three
observations.

\subsubsection{It is easy to set up reproducible numerical experiments}

The package manager makes it easy to reproduce the exact environment, including
binary dependencies. We have used this feature for all of our papers based on
\trixi \cite{schlottkelakemper2021purely, ranocha2021preventing}, including this
one \cite{ranocha2021adaptiveRepro}.
This facilitates code sharing and reproducible research in computational science,
which is arguably important but not mainstream yet \cite{barnes2010publish,
donoho2010invitation, leveque2013top}.

\subsubsection{External C libraries can be integrated relatively easily}

We have written a Julia wrapper\footnote{\url{https://github.com/trixi-framework/P4est.jl}}
of the C library \texttt{p4est} \cite{burstedde2011p4est}. In our experience,
it is relatively easy to do so in Julia and the package manager in combination
with BinaryBuilder.jl makes it convenient to distribute the necessary binaries.
In particular, users do not have to compile C libraries on their own system
and the binaries are available on all major platforms including Linux, Mac OS,
and Windows.

Similarly, there is no need to compile HDF5 on a user system due to the
availability of HDF5.jl. There is still work to be done how to improve the
experience in combination with MPI on high performance computing (HPC) clusters,
but some promising approaches exist \cite{byrne2021mpi}.

\subsubsection{Packages can really be used together at low (or no) cost}

Due to Julia's package manager, the cost of using external dependencies is low
enough to not be a problem. Traditionally, many scientific simulation codes tend
to reduce the number of external dependencies as much as possible due to the
complexity of handling different versions and making everything work together.
Such an approach often leads to a lot of code duplication. For example, many
CFD codes implement their own time integration methods, arguing that the spatial
part is much more complex. While this is often true, it is still more efficient
in terms of human workload to be able to reuse existing implementations. This
allows expert on time integration methods to develop specialized algorithms and
implement them in open source software while practitioners or researchers focusing
on spatial semidiscretizations ca benefit immediately by changing only one line
of code. For example, optimized time integration methods were developed in
\cite{ranocha2021optimized} and implemented in OrdinaryDiffEq.jl. Thus, they
can be used with \trixi by changing a single line of code. In contrast, researchers
working without external dependencies would need to use a day or two to digest
all the details and implement the methods in their own codes, making it much
less likely that they will do this and benefit from recent algorithmic developments.

An additional example is given by automatic differentiation. Due to dispatch,
it is conveniently possible to use forward mode automatic differentiation
\cite{revels2016forward} to compute Jacobians of semidiscretizations of nonlinear
conservation laws with \trixi or to differentiate through a complete simulation
including time integration methods from OrdinaryDiffEq.jl.

\subsubsection{The code base is simple enough to be useful for students}

Due to the package manager, \trixi and all related ODE and visualization tools
can be installed with a single command, reducing the overhead of exploring the
code. In addition, Julia's expressiveness and the ability to work with a restricted
subset of all possible features have enabled more than 18 students to use \trixi
for their coursework or theses. In our experience, the time required to get
started with traditional monolithic code bases is so long that students either
choose to build their own implementations specialized on their tasks or can only
work on toy problems since the remaining time is rather restricted.

\subsubsection{Existing features can be extended and combined easily}

Due to Julia's high-level programming approach, dynamic typing, and multiple
dispatch, it is easy to combine existing functionality efficiently. For example,
the single-physics solvers for hyperbolic PDEs of \trixi were extended to
a multi-physics setup for the compressible Euler equations with self-gravity
with roughly 350 lines of code \cite{schlottkelakemper2021purely}.
In addition, \trixi can be extended from the outside without modifying the main
source code, which makes it easy to set up new simulation approaches and analyze
existing ones, \eg by fluctuation simulations \cite{ranocha2021preventing}.


\subsection{What is still difficult or unknown}

\subsubsection{Compilation times can be annoying}

Since Julia uses a serial just-ahead-of-time compiler that does currently not cache
code between different Julia sessions, the initial compilation time can be
annoying. For example, the time to finish the first simulation in a fresh Julia
session and plot the results on a notebook can take between 30 seconds and a
minute. Having compiled the code, the second simulation and plot take less than
0.05 seconds. Thus, switching to Julia requires adapting the workflow compared
to other languages such as keeping a REPL session active for a longer time and
using packages such as Revise.jl\footnote{\url{https://github.com/timholy/Revise.jl}}.
This is particularly problematic in HPC environments. There are tools such as
PackageCompiler.jl\footnote{\url{https://github.com/JuliaLang/PackageCompiler.jl}}
that can help with these tasks but a good workflow usable for development and
deployment still has to be found.

\subsubsection{MPI-based parallel simulations need to be established}

MPI: To be evaluated but the basic tools are already there \cite{byrne2021mpi}

\todo{TODO: Michael, could you please write something here? You are much more
experienced with MPI and HPC} %TODO Michael


\section{Summary and conclusions}

\todo{TODO %TODO Summary
\begin{itemize}
  \item Learning a new programming language has some overhead but it pays off
\end{itemize}}



\section*{Acknowledgments}

We would like to thank all other contributors to and users of \trixi for their
help, encouragement, and discussions.
Funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation)
under Germany's Excellence Strategy EXC 2044-390685587, Mathematics MÃ¼nster:
Dynamics-Geometry-Structure.

\todo{TODO: Add your funding sources that need to be here (if any)} %TODO Funding


% References
\input{bib.tex}


\todo{ % TODO
\begin{itemize}
  \item Full paper: 5--10 pages
  \item Prepare repro repo including scripts for \trixi and Fluxo
  \item The title of our talk at JuliaCon is
  ``Adaptive and extendable numerical simulations with Trixi.jl''.
  Shall we use something like
  ``Adaptive high-order numerical simulations of hyperbolic PDEs with Trixi.jl:
  A case study of Julia for scientific computing'' for this paper?
  \item Restructure non-conservative stuff and add MHD benchmarks
  \item Add new features (Jesse's mesh and solver) to the list and update version, numer of examples, features, \etc
  \item Shall we re-create the schematic overview in tikz?
  \item Shall we compare \trixi to other open source frameworks such as MFEM, NGSolve, DealII, DUNE, FENICS, Firedrake, ClawPack, ...?
  \item Are there other aspects we should discuss?
\end{itemize}
\begin{quote}
  Compared to an extended abstract, a full paper presents more of the background
  and context motivating the work. It compares the work to other approaches taken
  in the field and gives some additional insights on the conference contribution.
  Use cases back up the work by showing how it can be used.
\end{quote}}


\end{document}

% Inspired by the International Journal of Computer Applications template
